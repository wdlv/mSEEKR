import argparse
import corefunctions
from scipy import stats
from itertools import product
import numpy as np
import pandas as pd

'''
This program compares the similarity of single sequence(found by command python mSEEKR.py. We call it ***hit sequence***) with input query sequence using
 background fasta files(lncRNA background sequences fasta) as a base.

Step 1:
    Calcualte the hit sequence and the query sequence's scaled kmer counts(count/kb of rna). 
Step 2:
    Calcualte the background fasta provided by users' scaled kmer count(count/kb of rna) and then get its mean and standard deviation
Step 3:
    Use hit sequence and query sequence's scaled kmer counts and background fasta's mean and stadnard deviation to get zscores
Step 4:
    Apply pearson correlation on two zscore list and get the correlation rate
Step 5:
    Create a new column of correlation rate for each hit sequence and add it to the dataframe file generated by command python mSEEKR.py
----------------------------------------------------------------------------------------------------------------------------------------
demoKmers: list
    a list of specific k length kmers
    Format example:
    k=3 ['AAA', 'AAT', 'AAC', 'AAG', 'ATA'....]
    k=4 ['AAAA', 'AAAT', 'AAAC', 'AAAG', 'AATA',....]
seqs: list
    a list of sequence reads without header
    Format example:
    ['AGGAGGAACAGTTGCCTCAGCACGTCTGCGCAGCTTTCCTTGCGGCGCCC', 'CTCCGCGTGGTCTATGATGGTGCATTTTGGTCCAGTCAGGCCCGGTGTGG', 'TCGGCCTCATTTTGGATTACTTCGGTGGGCTTCTCCTCGGCGTGGTTACG',....]

querySeq: one dimensional numpy array

kmerDataMatrix: N-dimensional numpy array (N depends on the number of sequence in a fasta file)

backgroundMean: one dimensional numpy array

backgroundStd: one dimensional numpy array

'''

#Load arguments, see help= for explanation
parser = argparse.ArgumentParser()
parser.add_argument('--queryFasta', type=str,help='Path to query fasta file', required=True)
parser.add_argument('--backgroundFasta', type=str,help='Path to lncRNA background sequences fasta file', required=True)
parser.add_argument('--backgroundMatrixMeanStd', type=str,help='Path to lncRNA background matrix mean and std generated from getBackgroundMatrixMeanStd.py. Note: backgroundMatrixMeanStd and backgroundFasta are using the same fasta file. The reason there are two commands is that computing mean and std of background fasta kmer seekr score requires too much resources', required=True)
parser.add_argument('--mSEEKRdataframeDir',type=str,help='Directory to read in the output dataframe generated from mSEEKR.py',default='./', required=True)
parser.add_argument('--minSeqLength',type=str,help='The minimum lenght of seq found',default='0')
parser.add_argument('--dir',type=str,help='Directory to save output dataframe',default='./')
parser.add_argument('--name',type=str,help='Name for output file',default='output')
parser.add_argument('-k',type=str,help='The same k value used in the mSEEKR.py step', required=True)
parser.add_argument('-a',type=str,help='String, Alphabet to generate k-mers (e.g. ATCG)',default='ATCG')

args = parser.parse_args()


if __name__ == '__main__':

    # Read in specified values of k, and the alphabet
    kVals = int(args.k)
    alphabet = args.a.upper()

    # Read in backgroundMatrix mean and std to calcuate probability density later
    bgMatrix = np.loadtxt(args.backgroundMatrixMeanStd)
    bgMatrixMean = bgMatrix[0]
    bgMatrixStd = bgMatrix[1]

    ### get mean and std; axis = 0 -> column | axis = 1 -> row

    # background fasta
    seqs = corefunctions.getCookedFasta(args.backgroundFasta)[1::2]
    backgroundKmerDataMatrix = corefunctions.getSeqsKmerProcessedCounts(seqs, kVals, alphabet)
    backgroundMean = np.mean(backgroundKmerDataMatrix, axis = 0)
    backgroundStd = np.std(backgroundKmerDataMatrix, axis = 0)

    # query fasta. Assume query fasta is one sequence. If not, merge multiple sequences to one sequence
    seqs = corefunctions.getCookedFasta(args.queryFasta)[1::2]

    if len(seqs) > 1:
        seqs = ''.join(seqs)
    else:
        seqs = seqs
        querySeq = corefunctions.getSeqsKmerProcessedCounts([seqs], kVals, alphabet)[0]
    querySeq = corefunctions.getSeqsKmerProcessedCounts(seqs, kVals, alphabet)[0]

    querySeqList = [querySeq.tolist()]

    # read in mSEEKR output dataframe
    minlength = int(args.minSeqLength)

    mseekrdf = pd.read_csv(args.mSEEKRdataframeDir, sep="\t")

    # convert all letters to uppercase
    mseekrdf['Sequence'] = [x.upper() for x in mseekrdf['Sequence']]

    hitsSeqs = [x for x in mseekrdf['Sequence'] if len(x)>=minlength]

    mseekrdf = mseekrdf[mseekrdf['Sequence'].isin(hitsSeqs)]

    hitsSeqList = []

    for singleSeq in hitsSeqs:
        oneSeq = corefunctions.getSeqsKmerProcessedCounts([singleSeq], kVals, alphabet)[0]
        hitsSeqList.append(oneSeq.tolist())
    

    # normalize data matrix with background fasta's mean and std
    querySeqList = (np.array(querySeqList) - backgroundMean) / backgroundStd
    hitsSeqList = (np.array(hitsSeqList) - backgroundMean) / backgroundStd


    # seekr pearson score
    seekrScoreMatrix = corefunctions.getSeekrScorePearson(querySeqList, hitsSeqList)

    # extract seekr pearson score from matrix
    pearsonlist = seekrScoreMatrix.tolist()[0]

    # calculate probability density
    probabilityDensityList = []

    for r in pearsonlist:
        currentProbabilityDensity = stats.norm.pdf(r, loc=bgMatrixMean, scale=bgMatrixStd)
        probabilityDensityList.append(currentProbabilityDensity)
    
    # add pearsonC list to mSEEKR dataframe
    mseekrdf['seekrPearsonCorr'] = pearsonlist

    # add probability density list to dataframe
    mseekrdf['probabilityDensity'] = probabilityDensityList

    mseekrdf.to_csv(args.mSEEKRdataframeDir,sep='\t', index=False)

