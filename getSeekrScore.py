import argparse
import corefunctions
from scipy import stats
from itertools import product
import numpy as np
import pandas as pd

'''
This program compares the similarity of single sequence(found by command python mSEEKR.py. We call it ***hit sequence***) with input query sequence using
 background fasta files(lncRNA background sequences fasta) as a base.

Step 1:
    Calcualte the hit sequence and the query sequence's scaled kmer counts(count/kb of rna). 
Step 2:
    Calcualte the background fasta provided by users' scaled kmer count(count/kb of rna) and then get its mean and standard deviation
Step 3:
    Use hit sequence and query sequence's scaled kmer counts and background fasta's mean and stadnard deviation to get zscores
Step 4:
    Apply pearson correlation on two zscore list and get the correlation rate
Step 5:
    Create a new column of correlation rate for each hit sequence and add it to the dataframe file generated by command python mSEEKR.py
----------------------------------------------------------------------------------------------------------------------------------------
demoKmers: list
    a list of specific k length kmers
    Format example:
    k=3 ['AAA', 'AAT', 'AAC', 'AAG', 'ATA'....]
    k=4 ['AAAA', 'AAAT', 'AAAC', 'AAAG', 'AATA',....]
seqs: list
    a list of sequence reads without header
    Format example:
    ['AGGAGGAACAGTTGCCTCAGCACGTCTGCGCAGCTTTCCTTGCGGCGCCC', 'CTCCGCGTGGTCTATGATGGTGCATTTTGGTCCAGTCAGGCCCGGTGTGG', 'TCGGCCTCATTTTGGATTACTTCGGTGGGCTTCTCCTCGGCGTGGTTACG',....]

querySeq: one dimensional numpy array

kmerDataMatrix: N-dimensional numpy array (N depends on the number of sequence in a fasta file)

backgroundMean: one dimensional numpy array

backgroundStd: one dimensional numpy array

'''

#Load arguments, see help= for explanation
parser = argparse.ArgumentParser()
parser.add_argument('--queryFasta', type=str,help='Path to query fasta file', required=True)
parser.add_argument('--backgroundFasta', type=str,help='Path to lncRNA background sequences fasta file; used to calculate mean and standard deviation for each k-mer', required=True)
parser.add_argument('--backgroundMatrixMeanStd', type=str,help='Path to lncRNA background matrix mean and std', required=True)
parser.add_argument('--mSEEKRdataframeDir',type=str,help='Directory to read in the output dataframe generated from command python mSEEKR.py',default='./', required=True)
parser.add_argument('--name',type=str,help='name for output file',default='output')
parser.add_argument('--dir',type=str,help='Directory to save output seekr score dataframe',default='./')
parser.add_argument('-k',type=str,help='The same k value used in the python mSEEKR.py step', required=True)
parser.add_argument('-a',type=str,help='String, Alphabet to generate k-mers (e.g. ATCG); default=ATCG',default='ATCG')

args = parser.parse_args()


if __name__ == '__main__':

    # Read in specified values of k, and the alphabet
    kVals = int(args.k)
    alphabet = args.a.upper()

    # Read in backgroundMatrix mean and std to calcuate probability density later
    bgMatrix = np.loadtxt(args.backgroundMatrixMeanStd)
    bgMatrixMean = bgMatrix[0]
    bgMatrixStd = bgMatrix[1]

    ### get mean and std; axis = 0 -> column | axis = 1 -> row

    # background fasta
    seqs = corefunctions.getCookedFasta(args.backgroundFasta)[1::2]
    backgroundKmerDataMatrix = corefunctions.getSeqsKmerProcessedCounts(seqs, kVals, alphabet)
    backgroundMean = np.mean(backgroundKmerDataMatrix, axis = 0)
    backgroundStd = np.std(backgroundKmerDataMatrix, axis = 0)

    # query fasta. Assume query fasta is one sequence. If not, merge multiple sequences to one sequence
    seqs = corefunctions.getCookedFasta(args.queryFasta)[1::2]

    if len(seqs) > 1:
        seqs = ''.join(seqs)
    else:
        seqs = seqs
        querySeq = corefunctions.getSeqsKmerProcessedCounts([seqs], kVals, alphabet)[0]
    querySeq = corefunctions.getSeqsKmerProcessedCounts(seqs, kVals, alphabet)[0]


    # read in mSEEKR output dataframe
    mseekrdf = pd.read_csv(args.mSEEKRdataframeDir, sep="\t")

    hitsSeqs = (x for x in mseekrdf['Sequence'])

    combinedSeqs = [querySeq.tolist()]

    for singleSeq in hitsSeqs:
        oneSeq = corefunctions.getSeqsKmerProcessedCounts([singleSeq], kVals, alphabet)[0]
        combinedSeqs.append(oneSeq.tolist())
    

    # normalize data matrix with background fasta's mean and std
    combinedSeqs = (np.array(combinedSeqs) - backgroundMean) / backgroundStd

    # row normalization
    normCombinedSeqs = corefunctions.rowNormalization(combinedSeqs)


    # seekr pearson score
    seekrScoreMatrix = corefunctions.getSeekrScorePearson(normCombinedSeqs)

    # extract seekr pearson score from matrix
    pearsonlist = seekrScoreMatrix.tolist()[0][1:]

    # calculate probability density
    probabilityDensityList = []

    for r in pearsonlist:
        currentProbabilityDensity = stats.norm.pdf(r, loc=bgMatrixMean, scale=bgMatrixStd)
        probabilityDensityList.append(currentProbabilityDensity)

    # # iterate each hits and get each's pearson correlation score
    # queryNormSeq = normSeqs[0]
    # for OneNormSeq in normSeqs[1:]:

    #     onePearCorr = getPearsonCorrelation(OneNormSeq, queryNormSeq, backgroundMean, backgroundStd)
    #     pearsonlist.append(onePearCorr)
    
    # add pearsonC list to mSEEKR dataframe
    mseekrdf['seekrPearsonCorr'] = pearsonlist

    # add probability density list to dataframe
    mseekrdf['probabilityDensity'] = probabilityDensityList

    mseekrdf.to_csv(args.mSEEKRdataframeDir,sep='\t', index=False)

