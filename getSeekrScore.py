import argparse
import corefunctions
from scipy import stats
from itertools import product
import numpy as np
import pandas as pd

'''
This program compares the similarity of single sequence(found by command python mSEEKR.py. We call it ***hit sequence***) with input query sequence using
 background fasta files(lncRNA background sequences fasta) as a base.

Step 1:
    Calcualte the hit sequence and the query sequence's scaled kmer counts(count/kb of rna). 
Step 2:
    Calcualte the background fasta provided by users' scaled kmer count(count/kb of rna) and then get its mean and standard deviation
Step 3:
    Use hit sequence and query sequence's scaled kmer counts and background fasta's mean and stadnard deviation to get zscores
Step 4:
    Apply pearson correlation on two zscore list and get the correlation rate
Step 5:
    Create a new column of correlation rate for each hit sequence and add it to the dataframe file generated by command python mSEEKR.py
----------------------------------------------------------------------------------------------------------------------------------------
demoKmers: list
    a list of specific k length kmers
    Format example:
    k=3 ['AAA', 'AAT', 'AAC', 'AAG', 'ATA'....]
    k=4 ['AAAA', 'AAAT', 'AAAC', 'AAAG', 'AATA',....]
seqs: list
    a list of sequence reads without header
    Format example:
    ['AGGAGGAACAGTTGCCTCAGCACGTCTGCGCAGCTTTCCTTGCGGCGCCC', 'CTCCGCGTGGTCTATGATGGTGCATTTTGGTCCAGTCAGGCCCGGTGTGG', 'TCGGCCTCATTTTGGATTACTTCGGTGGGCTTCTCCTCGGCGTGGTTACG',....]

querySeq: one dimensional numpy array

kmerDataMatrix: N-dimensional numpy array (N depends on the number of sequence in a fasta file)

backgroundMean: one dimensional numpy array

backgroundStd: one dimensional numpy array

'''

# preprocess the kmer counts
def getSeqsKmerProcessedCounts(seqs, k, alphabet):
    # get all the possible kmer combination
    demoKmers = [''.join(p) for p in product(alphabet, repeat=k)]

    # create a numpy array with initial value 0; 4 is equal to len(ATCG)
    kmerDataMatrix = np.zeros((len(seqs), 4**k), dtype=np.float32)

    for index, seq in enumerate(seqs):
        # create a dict with all kmers and initial value is 1
        kmerDict = dict.fromkeys(demoKmers, 1)

        # scale kmer count number to counts/kb of current sequence
        seq_length = len(seq)
        scaled_increment = 1000 / (seq_length - k + 1)
        #scaled_increment = 1 if seq_length <= 1000 else scaled_increment

        for i in range(0,seq_length-k+1):
            currentKmer = seq[i:i+k]
            if currentKmer in kmerDict:
                kmerDict[currentKmer] += scaled_increment
        
        onerow = list(kmerDict.values())

        # add scaled 1 to kmer whose count is 0
        # onerow = [scaled_increment if x==0 else x for x in onerow]

        # assign list value to numpy matrix's each row
        kmerDataMatrix[index] = np.asarray(onerow, dtype=np.float32)
    
    # log2 transform the count matrix
    kmerDataMatrix = np.log2(kmerDataMatrix)

    return kmerDataMatrix

# get a pearson correlation score of zscores calcuated from query and background fastas
# def getPearsonCorrelation(oneSeq, querySeq, backgroundMean, backgroundStd):

#     queryZscore = (querySeq - backgroundMean) / backgroundStd
#     backgroundZscore = (oneSeq - backgroundMean) / backgroundStd
#     oneSeqPearCorr = stats.pearsonr(queryZscore, backgroundZscore)[0]

#     return oneSeqPearCorr


def rowNormalization(inputSeqs):

    inputSeqs = (inputSeqs.T - np.mean(inputSeqs, axis=1)).T
    inputSeqs = (inputSeqs.T / np.std(inputSeqs, axis=1)).T

    return inputSeqs

def getSeekrScorePearson(inputMatrix):
    return np.inner(inputMatrix, inputMatrix) / inputMatrix.shape[1]



#Load arguments, see help= for explanation
parser = argparse.ArgumentParser()
parser.add_argument('--queryFasta', type=str,help='Path to query fasta file', required=True)
parser.add_argument('--backgroundFasta', type=str,help='Path to lncRNA background sequences fasta file; used to calculate mean and standard deviation for each k-mer', required=True)
parser.add_argument('--mSEEKRdataframeDir',type=str,help='Directory to read in the output dataframe generated from command python mSEEKR.py',default='./', required=True)
#parser.add_argument('--name',type=str,help='name for seekPearsonCorr file',default='out', required=True)
parser.add_argument('--dir',type=str,help='Directory to save output seekr score dataframe',default='./')
parser.add_argument('-k',type=str,help='The same k value used in the python mSEEKR.py step', required=True)
parser.add_argument('-a',type=str,help='String, Alphabet to generate k-mers (e.g. ATCG); default=ATCG',default='ATCG')

args = parser.parse_args()


if __name__ == '__main__':

    # Read in specified values of k, and the alphabet
    kVals = int(args.k)
    alphabet = args.a.upper()

    ### get mean and std; axis = 0 -> column | axis = 1 -> row

    # background fasta
    seqs = corefunctions.getCookedFasta(args.backgroundFasta)[1::2]
    kmerDataMatrix = getSeqsKmerProcessedCounts(seqs, kVals, alphabet)
    backgroundMean = np.mean(kmerDataMatrix, axis = 0)
    backgroundStd = np.std(kmerDataMatrix, axis = 0)

    # query fasta. Assume query fasta is one sequence. If not, merge multiple sequences to one sequence
    seqs = corefunctions.getCookedFasta(args.queryFasta)[1::2]

    if len(seqs) > 1:
        seqs = ''.join(seqs)
    else:
        seqs = seqs
        querySeq = getSeqsKmerProcessedCounts([seqs], kVals, alphabet)[0]
    querySeq = getSeqsKmerProcessedCounts(seqs, kVals, alphabet)[0]


    # read in mSEEKR output dataframe
    mseekrdf = pd.read_csv(args.mSEEKRdataframeDir, sep="\t")

    hitsSeqs = list(mseekrdf['Sequence'])

    combinedSeqs = [querySeq.tolist()]

    for singleSeq in hitsSeqs:
        oneSeq = getSeqsKmerProcessedCounts([singleSeq], kVals, alphabet)[0]
        combinedSeqs.append(oneSeq.tolist())
    

    # normalize data matrix with background fasta's mean and std
    combinedSeqs = (np.array(combinedSeqs) - backgroundMean) / backgroundStd

    # row normalization
    normCombinedSeqs = rowNormalization(combinedSeqs)


    # seekr pearson score
    seekrScoreMatrix = getSeekrScorePearson(normCombinedSeqs)

    # extract seekr pearson score from matrix
    pearsonlist = seekrScoreMatrix.tolist()[0][1:]

    print(pearsonlist)

    # # iterate each hits and get each's pearson correlation score
    # queryNormSeq = normSeqs[0]
    # for OneNormSeq in normSeqs[1:]:

    #     onePearCorr = getPearsonCorrelation(OneNormSeq, queryNormSeq, backgroundMean, backgroundStd)
    #     pearsonlist.append(onePearCorr)
    
    # add pearsonC list to mSEEKR dataframe
    mseekrdf['seekrPearsonCorr'] = pearsonlist

    mseekrdf.to_csv(args.mSEEKRdataframeDir,sep='\t', index=False)

